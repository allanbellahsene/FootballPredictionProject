{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, SGDRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import KFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after(text, string):\n",
    "    # Find and validate first part.\n",
    "    pos_str = text.rfind(string)\n",
    "    if pos_str == -1: return \"\"\n",
    "    # Returns chars after the found string.\n",
    "    adjusted_pos_str = pos_str + len(string)\n",
    "    if adjusted_pos_str >= len(text): return \"\"\n",
    "    return text[adjusted_pos_str:]\n",
    "\n",
    "def import_data(init_path, years):\n",
    "    total_data=[]\n",
    "    errors =[]\n",
    "    for year in years:\n",
    "        try:\n",
    "            path = init_path+year+'.csv'\n",
    "            data = pd.read_csv(path)\n",
    "            total_data.append(data)\n",
    "        except Exception as err:\n",
    "            errors.append(err)\n",
    "            bound = int(after(str(err), 'Expected')[1:3])\n",
    "            path = init_path+year+'.csv'\n",
    "            data = pd.read_csv(path, usecols=[i for i in range(bound)], encoding = 'unicode_escape')\n",
    "            total_data.append(data)\n",
    "            \n",
    "    for i in range(len(total_data)):\n",
    "        total_data[i] = delete_nan_column(total_data[i], 100)\n",
    "                \n",
    "    return total_data\n",
    "\n",
    "def delete_nan_column(data, max_number_of_nas):\n",
    "    data = data.loc[:, (data.isnull().sum(axis=0) <= max_number_of_nas)]\n",
    "    return data\n",
    "\n",
    "def merge_list(data):\n",
    "    df = pd.merge(data[0], data[1], 'outer')\n",
    "    for i in range(2, len(data)):\n",
    "        df = pd.merge(df, data[i], 'outer')\n",
    "    return df\n",
    "\n",
    "def choose_team(data, team, date):\n",
    "    \"\"\"\n",
    "    Output: returns all the data of a certain team available at time t-1 to predict a game a time t.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    return df.loc[((df['date'] < date) & (df['HomeTeam'] == team)) | (df['date'] < date) & (df['AwayTeam'] == team)] \n",
    "\n",
    "def choose_hometeam(data, team, date):\n",
    "    df = data.copy()\n",
    "    return df.loc[((df['date'] < date) & (df['HomeTeam'] == team))]\n",
    "\n",
    "def choose_awayteam(data, team, date):\n",
    "    df = data.copy()\n",
    "    return df.loc[((df['date'] < date) & (df['AwayTeam'] == team))]\n",
    "\n",
    "\n",
    "def last_results(team, game): \n",
    "    \n",
    "    w_bonus = 1 #+1 for a Win\n",
    "    d_bonus = 0 #0 for a Draw\n",
    "    l_malus = - w_bonus #-1 for a Loss\n",
    "    \n",
    "    if game['HomeTeam'] == team:\n",
    "        if game['FTR'] == 1:\n",
    "            global_perf = w_bonus\n",
    "        elif game['FTR'] == 2:\n",
    "            global_perf = l_malus\n",
    "        else:\n",
    "            global_perf = d_bonus\n",
    "        \n",
    "    if game['AwayTeam'] == team:\n",
    "        if game['FTR'] == 2:\n",
    "            global_perf = w_bonus\n",
    "        elif game['FTR'] == 1:\n",
    "            global_perf = l_malus\n",
    "        else:\n",
    "            global_perf = d_bonus\n",
    "\n",
    "    return global_perf\n",
    "\n",
    "def EWMA(data, team, date, feature, gamma):\n",
    "    \n",
    "    subdata = choose_team(data, team, date) #all data available at t-1 to use to predict outcome at date t\n",
    "        \n",
    "    perfs=[]\n",
    "    for i in range(len(subdata)):\n",
    "        previous_game = subdata.iloc[i] #compute performance for all games before game at date t\n",
    "        if feature == 'FTRH' or feature == 'FTRA':\n",
    "            perfs.append(last_results(team, previous_game))\n",
    "        else:\n",
    "            perfs.append(previous_game[feature]) #stores performances of all games that happened until t-1\n",
    "    \n",
    "    #gamma = 0.01\n",
    "    n = []\n",
    "    d = []\n",
    "    perf = [i for i in reversed(perfs)] #Now, perform an EWMA. To do so, we need to reverse the list, because\n",
    "    # we go from the most recent observation (i.e. game) to the earliest one. \n",
    "    \n",
    "    for i in range(len(perf)):\n",
    "        #Apply EWMA formula\n",
    "        coef = (1 - gamma)**i\n",
    "        nominator = perf[i] * coef\n",
    "        n.append(nominator)\n",
    "        denominator = coef\n",
    "        d.append(denominator)\n",
    "    momentum = sum(n) / sum(d)\n",
    "    \n",
    "    return momentum\n",
    "\n",
    "def clean_dataset(data):\n",
    "    new_data = data.copy()\n",
    "    from datetime import datetime\n",
    "    \n",
    "    dates = []\n",
    "    for i in range(len(new_data)):\n",
    "        date = new_data['Date'].iloc[i]\n",
    "        try:   \n",
    "            date = datetime.strptime(date, '%d/%m/%y')\n",
    "        except:\n",
    "            date = datetime.strptime(date, '%d/%m/%Y')   \n",
    "        dates.append(date)\n",
    "    dates = pd.DataFrame(dates, columns=['Date'])\n",
    "    new_data['date'] = dates\n",
    "    \n",
    "    new_data = new_data[['date', 'HomeTeam', 'AwayTeam', 'FTR', 'FTHG', 'FTAG', 'HS',\n",
    "                         'AS', 'HST', 'AST', 'HC', 'AC','HF', 'AF', 'B365H', 'B365D', \n",
    "                         'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', \n",
    "                         'LBA', 'PSH', 'PSD','PSA', 'WHH', 'WHD', 'WHA', 'VCH', 'VCD', \n",
    "                         'VCA', 'PSCH', 'PSCD', 'PSCA', 'BbAv<2.5', 'BbAv>2.5']]\n",
    "    \n",
    "    new_data.dropna(inplace=True)\n",
    "    new_data.reset_index(inplace=True)\n",
    "    new_data = new_data.drop(['index'], axis=1)\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "def get_labels(data, label):\n",
    "    Y = data[label]\n",
    "    Y = np.array(Y)\n",
    "    Y=Y.astype('int')\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def create_momentum_features(data, gamma, interval):\n",
    "    \n",
    "    k = interval[0]\n",
    "    l = interval[1]\n",
    "    \n",
    "    data_bis = data.copy()\n",
    "    \n",
    "    game_features = ['FTRH', 'FTRA', 'FTHG', 'FTAG', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF']\n",
    "    \n",
    "    for feature in game_features:\n",
    "        data_bis[feature + ' Momentum'] = np.nan\n",
    "        \n",
    "    home_features = ['FTRH', 'FTHG', 'HS', 'HC', 'HST', 'HF']\n",
    "    away_features = ['FTRA', 'FTAG', 'AS', 'AC', 'AST', 'AF']\n",
    "\n",
    "    \n",
    "    for i in range(k, l):\n",
    "        try:\n",
    "            date = data_bis['date'].iloc[i]\n",
    "            hometeam = data_bis['HomeTeam'].iloc[i]\n",
    "            awayteam = data_bis['AwayTeam'].iloc[i]\n",
    "            for feature in home_features:\n",
    "                data_bis[feature + ' Momentum'].iloc[i] = EWMA(data_bis, hometeam, date, feature, gamma)\n",
    "            for feature in away_features:\n",
    "                data_bis[feature + ' Momentum'].iloc[i] = EWMA(data_bis, awayteam, date, feature, gamma)\n",
    "\n",
    "        except:\n",
    "            print(i)\n",
    "           \n",
    "    new_data  = data_bis.dropna()\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "def get_features(data, features, normalize=True):\n",
    "    from sklearn.preprocessing import normalize\n",
    "    X = np.array(data[features])\n",
    "    if normalize:\n",
    "        X = normalize(X)\n",
    "    else:\n",
    "        X = X\n",
    "    \n",
    "    return X\n",
    "\n",
    "def convert_labels(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    df.loc[df.FTR == \"H\", \"FTR\"] = 1 #Replace nominal target variables by numbers\n",
    "    df.loc[df.FTR == \"D\", \"FTR\"] = 0\n",
    "    df.loc[df.FTR == \"A\", \"FTR\"] = 2\n",
    "    \n",
    "    return df\n",
    "\n",
    "def regression(dataset, algo, X, y1, y2, Kfold, train_set):\n",
    "    import random\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    test_accuracies=[]\n",
    "    models_home=[]\n",
    "    models_away=[]\n",
    "    \n",
    "    for n in random.sample(range(1,1000), Kfold):\n",
    "        X_train1, X_test1, y_home_train, y_home_test = train_test_split(X, y1, train_size=train_set,random_state=n)\n",
    "        X_train2, X_test2, y_away_train, y_away_test = train_test_split(X, y2, train_size=train_set,random_state=n)\n",
    "\n",
    "        model_home = algo().fit(X_train1, y_home_train)\n",
    "        models_home.append(model_home)\n",
    "        model_away = algo().fit(X_train2, y_away_train)\n",
    "        models_away.append(model_away)\n",
    "        \n",
    "    models = []\n",
    "    for homeModel in models_home:\n",
    "        for awayModel in models_away:\n",
    "            \n",
    "            y_home_hat = homeModel.predict(X).reshape((-1,1))\n",
    "            y_home_hat = np.round(y_home_hat)\n",
    "    \n",
    "            y_away_hat = awayModel.predict(X).reshape((-1,1))\n",
    "            y_away_hat = np.round(y_away_hat)\n",
    "        \n",
    "            home_coef = homeModel.coef_\n",
    "            home_intercept = homeModel.intercept_\n",
    "            w_home = np.insert(np.array(home_coef).reshape(-1,1), 0, home_intercept, axis=0)\n",
    "        \n",
    "            away_coef = awayModel.coef_\n",
    "            away_intercept = awayModel.intercept_\n",
    "            w_away = np.insert(np.array(away_coef).reshape(-1,1), 0, away_intercept, axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "            predictions = []\n",
    "            for i in range(len(y_home_hat)):\n",
    "                if y_home_hat[i] > y_away_hat[i]:\n",
    "                    predictions.append(1)\n",
    "                elif y_home_hat[i] < y_away_hat[i]:\n",
    "                    predictions.append(2)\n",
    "                else:\n",
    "                    predictions.append(0)\n",
    "    \n",
    "            predictions = np.array(predictions).reshape(-1,1)\n",
    "            true_result = np.array(dataset['FTR']).astype('int').reshape(-1,1)\n",
    "    \n",
    "            accuracy = len(predictions[predictions==true_result])/len(predictions)\n",
    "            models.extend(([accuracy], [w_home], [w_away]))\n",
    "            \n",
    "    models = np.array(models).reshape(-1, 3)\n",
    "    idx = np.argmax(models[:,0])\n",
    "    best_model = models[idx,:]\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def optimal_regressor(algo, X, y, kfold, metrics):\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.linear_model import LassoCV, LinearRegression, RidgeCV\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    \n",
    "    kf = KFold(n_splits=kfold, shuffle=False)\n",
    "    kf.split(X)\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Split train-test\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if algo == LassoCV or algo == RidgeCV:\n",
    "            model = algo(cv=kfold).fit(X_train, y_train.ravel())\n",
    "        elif algo == LinearRegression:\n",
    "            model = algo().fit(X_train, y_train.ravel())\n",
    "        else:\n",
    "            print('This algorithm is not available')\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        if metrics == 'MSE':\n",
    "            metric = mean_squared_error(y_test, y_pred, squared=True)\n",
    "        elif metrics == 'RMSE':\n",
    "            metric = mean_squared_error(y_test,y_pred, squared=False)\n",
    "        elif metrics == 'MAE':\n",
    "            metric = mean_absolute_error(y_test, y_pred)\n",
    "        else:\n",
    "            print('This metric is not available')\n",
    "            \n",
    "        error = metric\n",
    "        if algo == LassoCV:\n",
    "            algo_name = 'Lasso'\n",
    "        elif algo == RidgeCV:\n",
    "            algo_name = 'Ridge'\n",
    "        elif algo == LinearRegression:\n",
    "            algo_name = 'LinearRegression'\n",
    "        else:\n",
    "            print('This algorithm is not available')\n",
    "            \n",
    "        models.extend(([model], [algo_name], [error]))\n",
    "        \n",
    "    models = np.array(models).reshape(-1,3)\n",
    "    idx = np.argmin(models[:, 1])\n",
    "    opt_model = models[idx,:]\n",
    "        \n",
    "    return opt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 840 ms, sys: 26.6 ms, total: 867 ms\n",
      "Wall time: 898 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "personnal_path = '/Users/allanbellahsene/Desktop/'\n",
    "common_path = 'DATA_SCIENCE_PROJECT_ALLAN/data/LIGA/Liga_'\n",
    "path = personal_path + common_path\n",
    "years = ['2013', '2014', '2015', '2016', '2017', '2018', '2019']\n",
    "new_data = import_data(init_path=path, years=years)\n",
    "new_data=merge_list(new_data)\n",
    "new_data = clean_dataset(new_data)\n",
    "odds_features = ['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'LBH', 'LBD', \n",
    "                 'LBA', 'PSH', 'PSD','PSA', 'WHH', 'WHD', 'WHA', 'VCH', 'VCD', 'VCA', 'PSCH', 'PSCD', 'PSCA',\n",
    "                'BbAv<2.5', 'BbAv>2.5']\n",
    "momentum_features = ['FTHG Momentum', 'HS Momentum', 'HC Momentum', 'HST Momentum', 'HF Momentum',\n",
    "                     'FTAG Momentum', 'AS Momentum', 'AC Momentum', 'AST Momentum', 'AF Momentum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001 k: 0 Algo: LinearRegression Metrics: MSE Min_error: 0.05670906295043738\n",
      "Alpha: 0.001 k: 0 Algo: Lasso Metrics: MSE Min_error: 0.05360399983181919\n",
      "Alpha: 0.001 k: 0 Algo: Ridge Metrics: MSE Min_error: 0.06277929776994338\n",
      "Alpha: 0.001 k: 0 Algo: LinearRegression Metrics: MAE Min_error: 0.15330712946794753\n",
      "Alpha: 0.001 k: 0 Algo: Lasso Metrics: MAE Min_error: 0.1475695700540747\n",
      "Alpha: 0.001 k: 0 Algo: Ridge Metrics: MAE Min_error: 0.16657156928728714\n",
      "Alpha: 0.001 k: 0 Algo: LinearRegression Metrics: RMSE Min_error: 0.23813664764256126\n",
      "Alpha: 0.001 k: 0 Algo: Lasso Metrics: RMSE Min_error: 0.2315253762156952\n",
      "Alpha: 0.001 k: 0 Algo: Ridge Metrics: RMSE Min_error: 0.25055797287243403\n",
      "Alpha: 0.001 k: 3 Algo: LinearRegression Metrics: MSE Min_error: 0.045904536844969805\n",
      "Alpha: 0.001 k: 3 Algo: Lasso Metrics: MSE Min_error: 0.044434329497663655\n",
      "Alpha: 0.001 k: 3 Algo: Ridge Metrics: MSE Min_error: 0.053250493959726364\n",
      "Alpha: 0.001 k: 3 Algo: LinearRegression Metrics: MAE Min_error: 0.13913997758027338\n",
      "Alpha: 0.001 k: 3 Algo: Lasso Metrics: MAE Min_error: 0.1362472033966536\n",
      "Alpha: 0.001 k: 3 Algo: Ridge Metrics: MAE Min_error: 0.1546723783027148\n",
      "Alpha: 0.001 k: 3 Algo: LinearRegression Metrics: RMSE Min_error: 0.2142534406840875\n",
      "Alpha: 0.001 k: 3 Algo: Lasso Metrics: RMSE Min_error: 0.21079451961012566\n",
      "Alpha: 0.001 k: 3 Algo: Ridge Metrics: RMSE Min_error: 0.23076068547247464\n",
      "Alpha: 0.001 k: 5 Algo: LinearRegression Metrics: MSE Min_error: 0.053242744098672606\n",
      "Alpha: 0.001 k: 5 Algo: Lasso Metrics: MSE Min_error: 0.05160719103564891\n",
      "Alpha: 0.001 k: 5 Algo: Ridge Metrics: MSE Min_error: 0.06292299432101953\n",
      "Alpha: 0.001 k: 5 Algo: LinearRegression Metrics: MAE Min_error: 0.143202574513219\n",
      "Alpha: 0.001 k: 5 Algo: Lasso Metrics: MAE Min_error: 0.14063348947090712\n",
      "Alpha: 0.001 k: 5 Algo: Ridge Metrics: MAE Min_error: 0.16219070202753746\n",
      "Alpha: 0.001 k: 5 Algo: LinearRegression Metrics: RMSE Min_error: 0.23074389287405334\n",
      "Alpha: 0.001 k: 5 Algo: Lasso Metrics: RMSE Min_error: 0.22717216166522014\n",
      "Alpha: 0.001 k: 5 Algo: Ridge Metrics: RMSE Min_error: 0.25084456207185263\n",
      "Alpha: 0.01 k: 0 Algo: LinearRegression Metrics: MSE Min_error: 0.05658465045071355\n",
      "Alpha: 0.01 k: 0 Algo: Lasso Metrics: MSE Min_error: 0.05371041249320215\n",
      "Alpha: 0.01 k: 0 Algo: Ridge Metrics: MSE Min_error: 0.06294434769725615\n",
      "Alpha: 0.01 k: 0 Algo: LinearRegression Metrics: MAE Min_error: 0.15271884568029084\n",
      "Alpha: 0.01 k: 0 Algo: Lasso Metrics: MAE Min_error: 0.14776697375186715\n",
      "Alpha: 0.01 k: 0 Algo: Ridge Metrics: MAE Min_error: 0.1670595488480407\n",
      "Alpha: 0.01 k: 0 Algo: LinearRegression Metrics: RMSE Min_error: 0.23787528339597108\n",
      "Alpha: 0.01 k: 0 Algo: Lasso Metrics: RMSE Min_error: 0.2317550700485367\n",
      "Alpha: 0.01 k: 0 Algo: Ridge Metrics: RMSE Min_error: 0.25088712142566455\n",
      "Alpha: 0.01 k: 3 Algo: LinearRegression Metrics: MSE Min_error: 0.045808758195598195\n",
      "Alpha: 0.01 k: 3 Algo: Lasso Metrics: MSE Min_error: 0.04455776808043488\n",
      "Alpha: 0.01 k: 3 Algo: Ridge Metrics: MSE Min_error: 0.053408528573257556\n",
      "Alpha: 0.01 k: 3 Algo: LinearRegression Metrics: MAE Min_error: 0.13858605005872615\n",
      "Alpha: 0.01 k: 3 Algo: Lasso Metrics: MAE Min_error: 0.13632009748572435\n",
      "Alpha: 0.01 k: 3 Algo: Ridge Metrics: MAE Min_error: 0.15501999829891608\n",
      "Alpha: 0.01 k: 3 Algo: LinearRegression Metrics: RMSE Min_error: 0.2140298067924143\n",
      "Alpha: 0.01 k: 3 Algo: Lasso Metrics: RMSE Min_error: 0.2110871101712155\n",
      "Alpha: 0.01 k: 3 Algo: Ridge Metrics: RMSE Min_error: 0.23110285280207502\n",
      "Alpha: 0.01 k: 5 Algo: LinearRegression Metrics: MSE Min_error: 0.05333136872815543\n",
      "Alpha: 0.01 k: 5 Algo: Lasso Metrics: MSE Min_error: 0.051810809715684414\n",
      "Alpha: 0.01 k: 5 Algo: Ridge Metrics: MSE Min_error: 0.0632217771838515\n",
      "Alpha: 0.01 k: 5 Algo: LinearRegression Metrics: MAE Min_error: 0.14302246619491424\n",
      "Alpha: 0.01 k: 5 Algo: Lasso Metrics: MAE Min_error: 0.14078551147545626\n",
      "Alpha: 0.01 k: 5 Algo: Ridge Metrics: MAE Min_error: 0.16244155725633216\n",
      "Alpha: 0.01 k: 5 Algo: LinearRegression Metrics: RMSE Min_error: 0.2309358541416976\n",
      "Alpha: 0.01 k: 5 Algo: Lasso Metrics: RMSE Min_error: 0.22761987987802035\n",
      "Alpha: 0.01 k: 5 Algo: Ridge Metrics: RMSE Min_error: 0.25143941056217\n",
      "Alpha: 0.1 k: 0 Algo: LinearRegression Metrics: MSE Min_error: 0.054256667346523256\n",
      "Alpha: 0.1 k: 0 Algo: Lasso Metrics: MSE Min_error: 0.05355996285287397\n",
      "Alpha: 0.1 k: 0 Algo: Ridge Metrics: MSE Min_error: 0.06412181542894305\n",
      "Alpha: 0.1 k: 0 Algo: LinearRegression Metrics: MAE Min_error: 0.14393856926778412\n",
      "Alpha: 0.1 k: 0 Algo: Lasso Metrics: MAE Min_error: 0.1466629364065014\n",
      "Alpha: 0.1 k: 0 Algo: Ridge Metrics: MAE Min_error: 0.16861065361224936\n",
      "Alpha: 0.1 k: 0 Algo: LinearRegression Metrics: RMSE Min_error: 0.23293060628977733\n",
      "Alpha: 0.1 k: 0 Algo: Lasso Metrics: RMSE Min_error: 0.23143025483474275\n",
      "Alpha: 0.1 k: 0 Algo: Ridge Metrics: RMSE Min_error: 0.25322285724030336\n",
      "Alpha: 0.1 k: 3 Algo: LinearRegression Metrics: MSE Min_error: 0.04450187017830591\n",
      "Alpha: 0.1 k: 3 Algo: Lasso Metrics: MSE Min_error: 0.04467237299831345\n",
      "Alpha: 0.1 k: 3 Algo: Ridge Metrics: MSE Min_error: 0.05474555099643799\n",
      "Alpha: 0.1 k: 3 Algo: LinearRegression Metrics: MAE Min_error: 0.13203417170709983\n",
      "Alpha: 0.1 k: 3 Algo: Lasso Metrics: MAE Min_error: 0.13546165299548196\n",
      "Alpha: 0.1 k: 3 Algo: Ridge Metrics: MAE Min_error: 0.1566498648193235\n",
      "Alpha: 0.1 k: 3 Algo: LinearRegression Metrics: RMSE Min_error: 0.21095466379842354\n",
      "Alpha: 0.1 k: 3 Algo: Lasso Metrics: RMSE Min_error: 0.21135839940327295\n",
      "Alpha: 0.1 k: 3 Algo: Ridge Metrics: RMSE Min_error: 0.2339776720040568\n",
      "Alpha: 0.1 k: 5 Algo: LinearRegression Metrics: MSE Min_error: 0.05331008971082854\n",
      "Alpha: 0.1 k: 5 Algo: Lasso Metrics: MSE Min_error: 0.053120599351436745\n",
      "Alpha: 0.1 k: 5 Algo: Ridge Metrics: MSE Min_error: 0.06587412333067807\n",
      "Alpha: 0.1 k: 5 Algo: LinearRegression Metrics: MAE Min_error: 0.13835447380929444\n",
      "Alpha: 0.1 k: 5 Algo: Lasso Metrics: MAE Min_error: 0.14173063861351987\n",
      "Alpha: 0.1 k: 5 Algo: Ridge Metrics: MAE Min_error: 0.1646397608743696\n",
      "Alpha: 0.1 k: 5 Algo: LinearRegression Metrics: RMSE Min_error: 0.23088977827272592\n",
      "Alpha: 0.1 k: 5 Algo: Lasso Metrics: RMSE Min_error: 0.23047906488754405\n",
      "Alpha: 0.1 k: 5 Algo: Ridge Metrics: RMSE Min_error: 0.25665954751514325\n",
      "Alpha: 0.75 k: 0 Algo: LinearRegression Metrics: MSE Min_error: 0.05255104011442517\n",
      "Alpha: 0.75 k: 0 Algo: Lasso Metrics: MSE Min_error: 0.05010440762194567\n",
      "Alpha: 0.75 k: 0 Algo: Ridge Metrics: MSE Min_error: 0.06768989774458115\n",
      "Alpha: 0.75 k: 0 Algo: LinearRegression Metrics: MAE Min_error: 0.1356092628412203\n",
      "Alpha: 0.75 k: 0 Algo: Lasso Metrics: MAE Min_error: 0.1330258265006626\n",
      "Alpha: 0.75 k: 0 Algo: Ridge Metrics: MAE Min_error: 0.16938477773321636\n",
      "Alpha: 0.75 k: 0 Algo: LinearRegression Metrics: RMSE Min_error: 0.22924013635143645\n",
      "Alpha: 0.75 k: 0 Algo: Lasso Metrics: RMSE Min_error: 0.22384013854075785\n",
      "Alpha: 0.75 k: 0 Algo: Ridge Metrics: RMSE Min_error: 0.2601728228400906\n",
      "Alpha: 0.75 k: 3 Algo: LinearRegression Metrics: MSE Min_error: 0.043464795400938776\n",
      "Alpha: 0.75 k: 3 Algo: Lasso Metrics: MSE Min_error: 0.04204561332501957\n",
      "Alpha: 0.75 k: 3 Algo: Ridge Metrics: MSE Min_error: 0.058938818646384256\n",
      "Alpha: 0.75 k: 3 Algo: LinearRegression Metrics: MAE Min_error: 0.12594416387315022\n",
      "Alpha: 0.75 k: 3 Algo: Lasso Metrics: MAE Min_error: 0.12445558763342138\n",
      "Alpha: 0.75 k: 3 Algo: Ridge Metrics: MAE Min_error: 0.1604296557727098\n",
      "Alpha: 0.75 k: 3 Algo: LinearRegression Metrics: RMSE Min_error: 0.20848212249720305\n",
      "Alpha: 0.75 k: 3 Algo: Lasso Metrics: RMSE Min_error: 0.20505027023883574\n",
      "Alpha: 0.75 k: 3 Algo: Ridge Metrics: RMSE Min_error: 0.2427731835404896\n",
      "Alpha: 0.75 k: 5 Algo: LinearRegression Metrics: MSE Min_error: 0.05428231515154346\n",
      "Alpha: 0.75 k: 5 Algo: Lasso Metrics: MSE Min_error: 0.05303698669180156\n",
      "Alpha: 0.75 k: 5 Algo: Ridge Metrics: MSE Min_error: 0.07351473101777922\n",
      "Alpha: 0.75 k: 5 Algo: LinearRegression Metrics: MAE Min_error: 0.13327222124448726\n",
      "Alpha: 0.75 k: 5 Algo: Lasso Metrics: MAE Min_error: 0.13346645425550638\n",
      "Alpha: 0.75 k: 5 Algo: Ridge Metrics: MAE Min_error: 0.17289160428936937\n",
      "Alpha: 0.75 k: 5 Algo: LinearRegression Metrics: RMSE Min_error: 0.2329856543900149\n",
      "Alpha: 0.75 k: 5 Algo: Lasso Metrics: RMSE Min_error: 0.2302976046158569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.75 k: 5 Algo: Ridge Metrics: RMSE Min_error: 0.2711360009622094\n",
      "CPU times: user 4min 37s, sys: 5.22 s, total: 4min 42s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "home_features = ['FTHG', 'HS', 'HC', 'HST', 'HF']\n",
    "away_features = ['FTAG', 'AS', 'AC', 'AST', 'AF']\n",
    "game_features = home_features + away_features\n",
    "total_features = game_features + odds_features + momentum_features\n",
    "\n",
    "for alpha in [0.001, 0.01, 0.1, 0.75]:\n",
    "    for k in [0, 3, 5]:\n",
    "        data_bis = new_data.copy()\n",
    "        \n",
    "\n",
    "        for feature in game_features:\n",
    "            data_bis[feature + ' Momentum'] = np.nan\n",
    "    \n",
    "        home_teams = list(data_bis['HomeTeam'].unique())\n",
    "        away_teams = list(data_bis['AwayTeam'].unique())\n",
    "        max_date = max(data_bis['date'])\n",
    "\n",
    "        for home_feature in home_features:\n",
    "            for home_team in home_teams:\n",
    "                column = choose_hometeam(data_bis, home_team, max_date)[home_feature].ewm(alpha=alpha, min_periods=k).mean().shift(1, axis=0)\n",
    "                data_bis.loc[data_bis.HomeTeam == home_team, home_feature + \" Momentum\"] = column\n",
    "\n",
    "        for away_feature in away_features:\n",
    "            for away_team in away_teams:\n",
    "                column = choose_awayteam(data_bis, away_team, max_date)[away_feature].ewm(alpha=alpha, min_periods=k).mean().shift(1, axis=0)\n",
    "                data_bis.loc[data_bis.AwayTeam == away_team, away_feature + \" Momentum\"] = column\n",
    "\n",
    "        data_prov = data_bis.dropna()\n",
    "        \n",
    "        X = get_features(data_prov, total_features, normalize=True)\n",
    "        y = get_labels(data_prov, 'FTHG')\n",
    "        y = y.reshape(-1,1)\n",
    "\n",
    "        for metrics in ['MSE', 'MAE', 'RMSE']:\n",
    "            for algos in [LinearRegression, LassoCV, RidgeCV]:\n",
    "                model, algo_name, min_error = optimal_regressor(algos, X, y, kfold=10, metrics=metrics)\n",
    "                print('Alpha: ' + str(alpha), 'k: ' + str(k), 'Algo: ' + algo_name, 'Metrics: ' + metrics, 'Min_error: ' + str(min_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
